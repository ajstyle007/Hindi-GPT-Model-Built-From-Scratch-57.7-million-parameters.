{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ce32c8-7a93-455b-a143-c8dfa091d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3547a0-7265-4efc-a9e1-e9d9beebfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sentencepiece as spm\n",
    "from decoder_only_gpt import My_GPT_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "709e47db-942f-41fb-b9df-6b1ad171d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_only(model, ckpt_path, device):\n",
    "    state_dict = torch.load(ckpt_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=True)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"тЬЕ Loaded weights from {ckpt_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5252d6-4e15-47d7-8393-42a5ce628291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def generate(\n",
    "#     model,\n",
    "#     input_ids,\n",
    "#     max_new_tokens,\n",
    "#     temperature=0.6,\n",
    "#     top_p=0.9\n",
    "# ):\n",
    "#     model.eval()\n",
    "\n",
    "#     max_len = model.decoder.seq_len\n",
    "\n",
    "#     for _ in range(max_new_tokens):\n",
    "#         if input_ids.size(1) >= max_len:\n",
    "#             break\n",
    "\n",
    "#         logits = model(input_ids)\n",
    "#         logits = logits[:, -1, :] / temperature\n",
    "\n",
    "#         probs = torch.softmax(logits, dim=-1)\n",
    "\n",
    "#         sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
    "#         cumulative = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "#         mask = cumulative > top_p\n",
    "#         mask[..., 1:] = mask[..., :-1].clone()\n",
    "#         mask[..., 0] = False\n",
    "\n",
    "#         sorted_probs[mask] = 0\n",
    "#         sorted_probs /= sorted_probs.sum(dim=-1, keepdim=True)\n",
    "\n",
    "#         next_token = torch.multinomial(sorted_probs, 1)\n",
    "#         next_token = sorted_idx.gather(-1, next_token)\n",
    "\n",
    "#         input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "\n",
    "#     return input_ids\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model,\n",
    "    input_ids,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.5,\n",
    "    top_p=0.8,\n",
    "    repetition_penalty=1.5):\n",
    "    model.eval()\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        logits = model(input_ids)          # (B, T, V)\n",
    "        logits = logits[:, -1, :]          # last token\n",
    "\n",
    "        # ЁЯФе REPETITION PENALTY\n",
    "        if repetition_penalty != 1.0:\n",
    "            for i in range(input_ids.size(0)):\n",
    "                unique_tokens = torch.unique(input_ids[i])\n",
    "                logits[i, unique_tokens] /= repetition_penalty\n",
    "\n",
    "        # Temperature\n",
    "        logits = logits / temperature\n",
    "\n",
    "        # Top-p nucleus sampling\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        sorted_probs, sorted_idx = torch.sort(probs, descending=True)\n",
    "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "        # After zeroing out\n",
    "        sorted_probs = sorted_probs / sorted_probs.sum(dim=-1, keepdim=True)\n",
    "        \n",
    "        # Add this safety\n",
    "        sorted_probs = torch.nan_to_num(sorted_probs, nan=0.0)           # just in case\n",
    "        sorted_probs = torch.where(\n",
    "            sorted_probs.sum(dim=-1, keepdim=True) == 0,\n",
    "            torch.full_like(sorted_probs, 1.0 / sorted_probs.size(-1)),   # uniform if everything was cut\n",
    "            sorted_probs\n",
    "        )\n",
    "\n",
    "        next_token = torch.multinomial(sorted_probs, 1)\n",
    "        next_token = sorted_idx.gather(-1, next_token)\n",
    "\n",
    "        input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6e70745-fb83-4a22-b293-d391166f310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " тБЗ  рдкреНрд░рд╢реНрди: тБЗ рдлреНрд░рд╛рдВрд╕ рдХреА рд░рд╛рдЬрдзрд╛рдиреА рдХреНрдпрд╛ рд╣реИ? тБЗ  рдЙрддреНрддрд░: тБЗ  рд╕рдВрдШрд░реНрд╖ рдХрд╛ рдпрд╣ рд╢рд╣рд░ рдкреЗрд░рд┐рд╕, рдлреНрд░рд╛рдВрд╕ рдХреЗ рд╕рд╛рде рдЕрдкрдиреА рд╕реАрдорд╛ рд╕рд╛рдЭрд╛ рдХрд░рддрд╛ рд╣реИред рдФрд░ рдпрд╣ рджреБрдирд┐рдпрд╛ рднрд░ рдореЗрдВ рдХрдИ рдкреНрд░рдореБрдЦ рд╢рд╣рд░реЛрдВ рд╕реЗ рд╣реЛрдХрд░ рдмрд╣рддреА рд╣реИред рдкреЗрд░рд┐рд╕ рднреА рдЕрдкрдиреЗ рд╢рд╛рдирджрд╛рд░ рд╕рдореБрджреНрд░ рдкрд░рд┐рджреГрд╢реНрдп рдФрд░ рдЬреАрд╡рдВрдд рд╕рдВрд╕реНрдХреГрддрд┐ рдХреЗ рд▓рд┐рдП рдЬрд╛рдирд╛ рдЬрд╛рддрд╛ рд╣реИ, рдЬрд┐рд╕рдореЗрдВ рд▓реЛрдХрдкреНрд░рд┐рдп рдЖрдХрд░реНрд╖рдгреЛрдВ рдХреЛ рджреЗрдЦрдиреЗ рд╡рд╛рд▓реЗ рд▓реЛрдЧ рдмрд╣реБрдд рд╕рд╛рд░реЗ рдмрд╛рд░ рджрд┐рдЦрд╛рдИ рджреЗрддреЗ рд╣реИрдВред рдЗрд╕рдХреЗ рдЕрддрд┐рд░рд┐рдХреНрдд, рд▓реЗрдХрд░ рдЖрдИ. рдП. рдПрд╕. рдмреА. рд╕реА. рдкреНрд░рдгрд╛рд▓реА рдПрдХ рдкреНрд░рддрд┐рд╖реНрдард┐рдд рд╕реНрдерд▓реЛрдВ рдХрд╛ рдШрд░ рд╣реИ рдЬреЛ рдЗрд╕реЗ рджреБрдирд┐рдпрд╛ рдХреЗ рд╕рдмрд╕реЗ рдкреНрд░рд╕рд┐рджреНрдз рд╕реНрдерд▓реЛрдВ рдореЗрдВ рд╕реЗ рдПрдХ рдмрдирд╛рддрд╛ рд╣реИред рдПрдлрд┐рд▓ рдЯрд╛рд╡рд░ рдСрдл рд▓рд┐рдмрд░реНрдЯреА рдЬреИрд╕реЗ рдкреНрд░рддрд┐рд╖реНрдард┐рдд рд╕реНрдерд▓ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░рдиреЗ рд╡рд╛рд▓реА рдЗрд╕ рд╕рдВрд░рдЪрдирд╛ рдХреЛ рджреЛ рдореБрдЦреНрдп рдЪрд░рдгреЛрдВ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИрдГ тБЗ 1. рдлрд┐рд░, рдПрдлрд┐рд▓ рдЯрд╛рд╡рд░рдГ рдПрдлрд┐рд▓ рджреАрд╡рд╛рд░ рдкрд░ рд╕реНрдерд┐рдд рдПрдлрд┐рд▓рдВрдХреНрд╕ рдХреА \"рдж рд╡рд┐рдЪ рдПрдВрдб рдж рд▓рд┐рд▓реА\" рджреНрд╡рд╛рд░рд╛ рд╡рд┐рдХрд╕рд┐рдд рдПрдХ рдкреНрд░рд╛рдЪреАрди рдорд╣рд▓ рдХреЛ рдбрд┐рдЬрд╛рдЗрди рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред рдЗрд╕рдореЗрдВ рдПрдХ рдмрдбрд╝рд╛ рд╕рд╛рд╕рд╛реБрде-рдХреАрдк рд╕реЗ рд▓реЗрдХрд░ рдПрдХ рд╡рд┐рд╢рд╛рд▓ рд╢рд╣рд░ рддрдХ рд╕рдм рдХреБрдЫ рд╢рд╛рдорд┐рд▓ рдерд╛ред тБЗ 2. рдкреЗрд░рд┐рд╕рдГ рдПрдлрд┐рд▓рдкрдпреЛрдЧ рдХрд┐рдП рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдХрд┐рд╕реА рднреА рдкреНрд░рдХрд╛рд░ рдХреЗ рдЕрдореЗрд░рд┐рдХреА рд╣реИрдВрдбреЛрдкрд┐рдпрди рд╢реИрд▓реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдлрд┐рд▓рд╕реНрдЯрди рдХреЛ рдмрдирд╛рдпрд╛ рдЧрдпрд╛ рдерд╛ред рдЗрд╕рдХрд╛ рдирд┐рд░реНрдорд╛рдг 1863 рд╕реЗ 1900 рдХреЗ рджрд╢рдХ рдХреЗ рдЕрдВрдд рдореЗрдВ рд╢реБрд░реВ рд╣реБрдЖ рдерд╛ред тБЗ 3. рдПрдлрд┐рд▓рд┐рдХрд╛рдГ рдПрдлрд┐рд▓рд┐рдХрд╛ рдПрдХ рдРрд╕рд╛ рдкреНрд░рддреАрдХ рд╣реИ рдЬрд┐рд╕рдХрд╛ рдЙрдкрдпреЛрдЧ рдЖрдорддреМрд░ рдкрд░ рдЗрд╕рдХреА рд╡рд╛рд╕реНрддреБрдХрд▓рд╛ рдореЗрдВ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ, рдЬрд┐рд╕рдХрд╛ рдЕрд░реНрде рд╣реИ рдХрд┐ рдЗрд╕реЗ рджреБрдирд┐рдпрд╛ рдХреА рд╕рдмрд╕реЗ рдмрдбрд╝реА рдЗрдорд╛рд░рддреЛрдВ рдореЗрдВ рд╕реЗ рдПрдХ рдорд╛рдирд╛ рдЬрд╛рддрд╛ рд╣реИ рдФрд░ рдпрд╣ рдЕрдм рддрдХ рдХреА рд╕рдмрд╕реЗ рдЕрдзрд┐рдХ рдЬреНрдЮрд╛рдд рдХрд▓рд╛рдХреГрддрд┐рдпреЛрдВ рдореЗрдВ рд╕реЗ рдПрдХ рдмрди рдЧрдИ рд╣реИред рдпрд╣ рдХрд┐рд╕реА рднреА рд╕рдордп рджреБрдирд┐рдпрд╛ рдХреА рд╕рдмрд╕реЗ рдкреНрд░рднрд╛рд╡рд╢рд╛рд▓реА рд╡рд╕реНрддреБрдУрдВ рдореЗрдВ рд╕реЗ рдПрдХ рдмрдирд╛ рд╣реБрдЖ рд╣реИред тБЗ 4. рдкреЗрд░рд┐рд╕рдГ рдПрдлрд┐рд▓рд┐рдХрд╛ рдПрдХ рдРрд╕реА рдЬрдЧрд╣ рд╣реИ рдЬрд╣рд╛рдБ рдЖрдк рдЕрдкрдиреА рдЦреБрдж рдХреА рдкреНрд░рд╛рдХреГрддрд┐рдХ рд╕реБрдВрджрд░рддрд╛ рдФрд░ рд╕рд╛рдВрд╕реНрдХреГрддрд┐рдХ рдорд╣рддреНрд╡ рдХреЛ рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВред рдкрд╣рд▓реА рдирдЬрд╝рд░ рдореЗрдВ, рдкреЗрд░рд┐рд╕ рдПрдХ рдорд╣рд╛рди рдЖрд╢реНрдЪрд░реНрдп рд╣реИ рдЬреЛ рд╣рд░ рд╕рд╛рд▓ рд▓рд╛рдЦреЛрдВ рдЖрдЧрдВрддреБрдХреЛрдВ рдХреЛ рдЖрдХрд░реНрд╖рд┐рдд рдХрд░рддрд╛ рд╣реИред тБЗ 5. рдкреЗрд░рд┐рд╕рдГ рдПрдлрд┐рд▓рдкрд░ рдХреА рд╡рд┐рд╢реНрд╡ рдЗрддрд┐рд╣рд╛рд╕ рдФрд░ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдорд╣рддреНрд╡ рдХрд╛ рдкреНрд░рддреАрдХ рд╣реИ, рдФрд░ рдпрд╣ рдПрдлрд┐рд▓рдк рдХреЛ рджреБрдирд┐рдпрд╛ рдХреЗ рд╕рдмрд╕реЗ рдкреНрд░рд╕рд┐рджреНрдз рд╕реНрдерд▓реЛрдВ рдореЗрдВ рд╕реЗ рдПрдХ рдмрдирд╛рддрд╛ рд╣реИред рдЗрд╕рдХрд╛ рдкреНрд░рднрд╛рд╡ рджреБрдирд┐рдпрд╛ рднрд░ рдореЗрдВ рдорд╣рд╕реВрд╕ рдХрд┐рдпрд╛ рдЬрд╛ рд░рд╣рд╛ рд╣реИред тБЗ рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░, рдПрдлрд┐рд▓ рднреМрддрд┐рдХ рд╕реНрдерд╛рди рдФрд░ рд╕рдореГрджреНрдз рд╕рдВрд╕реНрдХреГрддрд┐ рдХреЗ рдХрд╛рд░рдг рдкреЗрд░рд┐рд╕ рдПрдХ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдХреЗрдВрджреНрд░ рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░рддрд╛ рд╣реИ, рдФрд░ рдЗрд╕рдХрд╛ рд╡реНрдпрд╛рдкрдХ рд░реВрдк рд╕реЗ рд╡рд┐рднрд┐рдиреНрди рд╕рдВрд╕реНрдХреГрддрд┐рдпреЛрдВ рдФрд░ рд╕рдВрд╕реНрдХреГрддрд┐рдпреЛрдВ рдХреЗ рд▓реЛрдЧреЛрдВ рджреНрд╡рд╛рд░рд╛ рдЖрдирдВрдж рд▓рд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред рд╣рд╛рд▓рд╛рдБрдХрд┐, рдпрд╣ рд╢рд╣рд░ рдХреА рд╡рд┐рд╡рд┐рдзрддрд╛ рдХрд╛ рд▓рд╛рдн рдЙрдард╛рдиреЗ рдХрд╛ рдПрдХ рдФрд░ рддрд░реАрдХрд╛ рд╣реИред рдЕрдкрдиреЗ рд╕реБрдВрджрд░ рджреГрд╢реНрдпреЛрдВ, рд╡рд┐рд╡рд┐рдз рд╡реНрдпрдВрдЬрдиреЛрдВ рдФрд░ рдЖрдХрд░реНрд╖рдгреЛрдВ рдХреЗ рд▓рд┐рдП рдЬрд╛рдирд╛ рдЬрд╛рддрд╛ рд╣реИ, рдФрд░ рдпрд╣ рд╕рднреА рдЙрдореНрд░ рдХреЗ рджрд░реНрд╢рдХреЛрдВ рдХреЗ рд▓рд┐рдП рдмрд╣реБрдд рдЕрдЪреНрдЫрд╛ рд╣реИред рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░, рдпрд╣ рдПрдХ рдЖрд╢реНрдЪрд░реНрдпрдЬрдирдХ рдЧрдВрддрд╡реНрдп рд╣реИ, рдЬреЛ рдЕрдкрдиреА рдЕрдиреВрдареА рд╡рд┐рд╢реЗрд╖рддрд╛рдУрдВ, рдЕрджреНрд╡рд┐рддреАрдп рд╕рдВрд╕реНрдХреГрддрд┐ рдФрд░ рд╕рдореГрджреНрдз\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"hindi_tokenizer_new.model\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = My_GPT_model(\n",
    "    vocab_size=32768,\n",
    "    num_layers=12,\n",
    "    d_model=512,     # ЁЯФе SAME AS CHECKPOINT\n",
    "    d_ff=2048,       # ЁЯФе SAME\n",
    "    num_heads=8,\n",
    "    seq_len=512\n",
    ").to(DEVICE)\n",
    "\n",
    "state_dict = torch.load(\"full_sft_epoch4_step10000.pt\", map_location=DEVICE)\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.eval()\n",
    "\n",
    "prompt = \"### рдкреНрд░рд╢реНрди:\\nрдлреНрд░рд╛рдВрд╕ рдХреА рд░рд╛рдЬрдзрд╛рдиреА рдХреНрдпрд╛ рд╣реИ?\\n\\n### рдЙрддреНрддрд░:\\n\"\n",
    "prompt_ids = torch.tensor([sp.encode(prompt)], device=DEVICE)\n",
    "\n",
    "max_new = model.decoder.seq_len - prompt_ids.size(1) - 1\n",
    "\n",
    "out = generate(model, prompt_ids, max_new_tokens=max_new)\n",
    "print(sp.decode(out[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4daebd5c-8bbf-4052-8a06-db0e719e21f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "My_GPT_model(\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(32768, 512)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Decoder_GPT_Block(\n",
       "        (swi_glu): SwiGLU_FFN(\n",
       "          (w1): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (w2): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (w3): Linear(in_features=1536, out_features=512, bias=False)\n",
       "          (act): SiLU()\n",
       "        )\n",
       "        (masked_mha): Masked_MHA(\n",
       "          (Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (K): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (V): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (fc_out): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (rms_norm0): RMSNorm()\n",
       "        (rms_norm1): RMSNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32768, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"hindi_tokenizer_new.model\")\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = My_GPT_model(\n",
    "    vocab_size=32768,\n",
    "    num_layers=12,\n",
    "    d_model=512,     # ЁЯФе SAME AS CHECKPOINT\n",
    "    d_ff=2048,       # ЁЯФе SAME\n",
    "    num_heads=8,\n",
    "    seq_len=512\n",
    ").to(DEVICE)\n",
    "\n",
    "state_dict = torch.load(\"full_sft_epoch5_step10000.pt\", map_location=DEVICE)\n",
    "model.load_state_dict(state_dict, strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f903ad08-cfac-4855-9ac7-06f0197654ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"рдорд╣рд╛рддреНрдорд╛ рдЧрд╛рдВрдзреА рдХреА рдЬреАрд╡рдиреА: рдорд╣рд╛рддреНрдорд╛ рдЧрд╛рдВрдзреА, рдЬрд┐рдиреНрд╣реЗрдВ рдмрд╛рдкреВ рдХрд╣рд╛ рдЬрд╛рддрд╛ рд╣реИ, рднрд╛рд░рдд рдХреЗ рд╕реНрд╡рддрдВрддреНрд░рддрд╛ рд╕рдВрдЧреНрд░рд╛рдо рдХреЗ рдкреНрд░рдореБрдЦ рдиреЗрддрд╛ рдереЗред рдЙрдирдХрд╛ рдЬрдиреНрдо 2 рдЕрдХреНрдЯреВрдмрд░ 1869 рдХреЛ рд╣реБрдЖ рдерд╛ред\"\"\"\n",
    "\n",
    "question = \"рдлреНрд░рд╛рдВрд╕ рдХреА рд░рд╛рдЬрдзрд╛рдиреА рдХреНрдпрд╛ рд╣реИ?\"\n",
    "\n",
    "prompt = f\"рд╕рд┐рд░реНрдл рдиреАрдЪреЗ рджрд┐рдП рд╕рдВрджрд░реНрдн рд╕реЗ рд╣реА рдЬрд╡рд╛рдм рджреЗрдВ:\\n\\nрд╕рдВрджрд░реНрдн:\\n{context}\\n\\nрдкреНрд░рд╢реНрди:\\n{question}\\n\\nрдЙрддреНрддрд░:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77f0f072-37e3-4e83-9f99-3a51e22c11b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  982,  1688,   863,  4694,    32,   107,  1490,   884, 28911,     1,\n",
       "         28851,   123,    30, 28875, 28911,     1,  9489,  2261,  1187,    26,\n",
       "         16462, 28911,  5209,  1187, 28879,  2774, 10457,   149,   376,    15,\n",
       "         28879,   329,    11,  3767, 10319,    11,  1237,   950,   241, 28869,\n",
       "           834,  1424,  2704,  2227, 12589, 28948, 28940,    28,   382,   132,\n",
       "         28869,     1,   571,  2326, 28911,     1,  2908,  1559,    26,  2375,\n",
       "           496,    15, 28910,     1, 16102, 28911]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_ids = torch.tensor([sp.encode(prompt)], device=DEVICE)\n",
    "prompt_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3de6e59-a081-4e40-89b2-86664acc9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "EOS_ID = sp.eos_id()\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model,\n",
    "    input_ids,\n",
    "    max_new_tokens=100,\n",
    "    temperature=0.6,\n",
    "    top_p=0.75,\n",
    "    repetition_penalty=1.5,\n",
    "    top_k=50\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits = model(input_ids)\n",
    "        next_logits = logits[:, -1, :]\n",
    "\n",
    "        # Repetition penalty\n",
    "        if repetition_penalty != 1.0:\n",
    "            for i in range(input_ids.size(0)):\n",
    "                unique_tokens = torch.unique(input_ids[i])\n",
    "                for token_id in unique_tokens:\n",
    "                    if next_logits[i, token_id] < 0:\n",
    "                        next_logits[i, token_id] *= repetition_penalty\n",
    "                    else:\n",
    "                        next_logits[i, token_id] /= repetition_penalty\n",
    "\n",
    "        # Temperature scaling\n",
    "        next_logits = next_logits / temperature\n",
    "\n",
    "        probs = torch.softmax(next_logits, dim=-1)\n",
    "\n",
    "        # Top-k filtering\n",
    "        if top_k > 0:\n",
    "            top_k_vals, top_k_indices = torch.topk(probs, top_k)\n",
    "            probs_zeroed = torch.zeros_like(probs).scatter_(-1, top_k_indices, top_k_vals)\n",
    "            probs = probs_zeroed / top_k_vals.sum(dim=-1, keepdim=True)\n",
    "\n",
    "        # Top-p nucleus filtering\n",
    "        sorted_probs, sorted_indices = torch.sort(probs, descending=True)\n",
    "        cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
    "\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = False\n",
    "        sorted_probs[sorted_indices_to_remove] = 0.0\n",
    "\n",
    "        # Renormalize\n",
    "        if sorted_probs.sum() == 0:\n",
    "            next_token = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            sorted_probs /= sorted_probs.sum(dim=-1, keepdim=True)\n",
    "            next_token = torch.multinomial(sorted_probs, num_samples=1)\n",
    "            next_token = sorted_indices.gather(-1, next_token)\n",
    "\n",
    "        input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "\n",
    "        # рдЕрдЧрд░ EOS token рд╣реЛ рддреЛ рдмреНрд░реЗрдХ (рдЕрдЧрд░ defined рд╣реИ)\n",
    "        if next_token.item() == EOS_ID:\n",
    "            break\n",
    "\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eff75392-abc4-43cd-a6ef-0aef72488be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "рднрд╛рд░рдд рдХреЗ рд╕реНрд╡рддрдВрддреНрд░ рд░реВрдк рд╕реЗ рд░рд╣рдиреЗ рд╡рд╛рд▓реЗ рд╡реНрдпрдХреНрддрд┐ рдХрд╛ рдирд╛рдо рдХреМрди рд╕рд╛ рд╣реИ? рдЙрдирдХреЗ рдЬрдиреНрдо рдХреЗ рдмрд╛рдж рдЙрдиреНрд╣реЗрдВ рдХрд┐рд╕ рджреЗрд╢ рдпрд╛ рдХреНрд╖реЗрддреНрд░ рдХреА рд╕рдмрд╕реЗ рдЕрдзрд┐рдХ рдЖрд╡рд╢реНрдпрдХрддрд╛ рдереА? рдЙрдирдХреА рдореГрддреНрдпреБ рдХреЗ рдмрд╛рдж рдЙрдирдХреЗ рд▓рд┐рдП рдХреМрди рд╕реА рдЙрдкрд▓рдмреНрдз рдереА? рд╡реЗ рдХрд┐рд╕ рд░рд╛рдЬреНрдп рдореЗрдВ рд░рд╣рддреЗ рд╣реИрдВ рдФрд░ рдЙрдирдХреЗ рдкрд╛рд╕ рдХреМрди рд╕рд╛ рдШрд░ рд╣реИ? рдпрд╣ рдзреНрдпрд╛рди рд░рдЦрдирд╛ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ рдХрд┐ рдЙрдирдХреЗ рд╕рд╛рде рдПрдХ рдЕрдЪреНрдЫрд╛ рд╕рдордп рдмрд┐рддрд╛рдиреЗ рд╕реЗ рдЙрдирдХреЗ рдЬреАрд╡рди рдкрд░ рд╕рдХрд╛рд░рд╛рддреНрдордХ рдкреНрд░рднрд╛рд╡ рдкрдбрд╝ рд╕рдХрддрд╛ рд╣реИред тБЗ рдЕрдВрддрддрдГ, рдпрджрд┐ рд╕рдВрджрд░реНрдн рдореЗрдВ рдХрд┐рд╕реА рдЕрдиреНрдп рджреЗрд╢ рдХреЗ рд▓реЛрдЧреЛрдВ рдиреЗ рдЗрд╕ рд╕реНрдерд┐рддрд┐ рд╕реЗ рдирд┐рдкрдЯрдиреЗ рдХреЗ рд▓рд┐рдП рдХреЛрдИ рдХрджрдо рдЙрдард╛рдП рд╣реИрдВ, рддреЛ рдЙрдиреНрд╣реЗрдВ рдЙрдЪрд┐рдд рдкреНрд░рддрд┐рдХреНрд░рд┐рдпрд╛ рдФрд░ рд╕рдорд░реНрдерди рдкреНрд░рд╛рдкреНрдд рд╣реЛрдЧрд╛ред рдЗрд╕рдХреЗ рдЕрддрд┐рд░рд┐рдХреНрдд, рдпрджрд┐ рдЖрдк рдХрд┐рд╕реА рдРрд╕реЗ рд╡реНрдпрдХреНрддрд┐ рдХреА рддрд▓рд╛рд╢ рдХрд░ рд░рд╣реЗ рд╣реИрдВ рдЬреЛ рдЕрдкрдиреА рдкреВрд░реА рдХреНрд╖рдорддрд╛ рддрдХ рдкрд╣реБрдВрдЪрдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реЛ, рддреЛ рдореБрдЭреЗ рдЖрдЧреЗ рдмрдврд╝рдиреЗ рдФрд░ рдЕрдкрдиреЗ рд▓рдХреНрд╖реНрдпреЛрдВ рддрдХ рдкрд╣реБрдВрдЪрдиреЗ рдореЗрдВ рдорджрдж рдХрд░рдиреЗ рдореЗрдВ рдЦреБрд╢реА рд╣реЛрдЧреАред тБЗ рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░, рдЬрдмрдХрд┐ рдореИрдВ рдпрд╣ рдпрд╛рдж рд░рдЦреВрдВрдЧрд╛ рдХрд┐ рдХрд┐рд╕реА рднреА рд╕реНрдерд╛рди рдкрд░ рдирд┐рд░реНрдгрдп рд▓реЗрдиреЗ рдореЗрдВ рд╣рдореЗрд╢рд╛ рдЦреБрд╢реА рд╣реЛрддреА рд╣реИ рдФрд░ рдореБрдЭреЗ рдЕрдкрдиреЗ рд▓рдХреНрд╖реНрдпреЛрдВ рддрдХ рдкрд╣реБрдВрдЪрдиреЗ рдореЗрдВ рдЦреБрд╢реА рд╣реЛрдЧреА, рдпрд╣ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ рдХрд┐ рд╣рдо рдЕрдкрдиреЗ рдЬреАрд╡рди рдХреЗ рд╕рднреА рдкрд╣рд▓реБрдУрдВ рдкрд░ рд╡рд┐рдЪрд╛рд░ рдХрд░реЗрдВ рдФрд░ рдЕрдкрдиреЗ рднрд╡рд┐рд╖реНрдп рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЕрдзрд┐рдХ рд╕реВрдЪрд┐рдд рд░рд╣реЗрдВред \"рдЗрд╕ рдорд╛рдорд▓реЗ рдореЗрдВ, рд╣рдо рдПрдХ рдмреЗрд╣рддрд░ рджреБрдирд┐рдпрд╛ рдмрдирд╛ рд╕рдХрддреЗ рд╣реИрдВ рдЬрд╣рд╛рдБ рд╣рд░ рдХреЛрдИ рдЕрдкрдиреЗ рд╕рдкрдиреЛрдВ рдХреЛ рдЕрдкрдирд╛рддрд╛ рд╣реИ рдФрд░ рдЕрдкрдиреЗ рдЬреАрд╡рди рдХреЛ рдЖрдЧреЗ рдмрдврд╝рд╛рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реЛ рд╕рдХреЗред рд╣рдо рдПрдХ рдРрд╕рд╛ рд╡рд╛рддрд╛рд╡рд░рдг рдмрдирд╛рдиреЗ рдореЗрдВ рднреА рд╢рд╛рдорд┐рд▓ рд╣реЛрдВрдЧреЗ рдЬрд╣рд╛рдВ рд╣рдо рдЕрдкрдиреЗ рдЖрд╕рдкрд╛рд╕ рдХреЗ рд▓реЛрдЧ рдЕрдкрдиреА рд░реБрдЪрд┐рдпреЛрдВ рдФрд░ рдЕрдиреБрднрд╡реЛрдВ рдХреЛ рд╕рд╛рдЭрд╛ рдХрд░рддреЗ рд╣реБрдП рдорд╣рд╕реВрд╕ рдХрд░рддреЗ рд╣реИрдВред \"рд╣рдо рдЬреЛ рдХреБрдЫ рднреА рдкрд╛рддреЗ рд╣реИрдВ, рд╣рдо рдЬреЛ рдЬрд╛рдирддреЗ рд╣реИрдВ рдХрд┐ рд╣рдо рдЕрдкрдиреЗ рдЬреАрд╡рди рдЬреА рд╕рдХрддреЗ рд╣реИрдВ, рд╣рдо рдЬреАрд╡рди рдЬреАрдиреЗ рдХреЗ рддрд░реАрдХреЗ рд╕реЗ рд░рд╣ рд╕рдХрддреЗ рд╣реИрдВред \"рдпрд╣ рд╣рдорд╛рд░реА рдпрд╛рддреНрд░рд╛ рдЙрди рддрд░реАрдХреЛрдВ рд╕реЗ рдХрд╛рдо рдХрд░рдиреЗ рдХреА рдЬрдЧрд╣ рд╣реИ рдЬреЛ рд╣рдо рд╕рд╛рдЭрд╛ рдХрд░рддреЗ рд╣реИрдВред рд╣рдо рдЬреАрд╡рди рдЬреАрдиреЗ рдХреЗ рдорд╛рдзреНрдпрдо рд╣реЛрддреЗ рд╣реИрдВ рдЬреЛ рд╣рдо рдЬреЛ рд╣рдорд╛рд░реЗ рдЬреАрд╡рди рдХреЗ рдорд╛рдзреНрдпрдо рд╕реЗ рдХрд╛рдо рдХрд░рддреЗ рд╣реИрдВ, рд╣рдо рд╣рдо рдЕрдкрдиреЗ рд░рд╛рд╕реНрддреЗ рджреЗрдЦрддреЗ рд╣реИрдВред рд╣рдо рдЕрдкрдиреЗ рдЬреАрд╡рди рдЬреА рд╕рдХрддреЗ рд╣реИрдВред рд╣рдо рд╣реИрдВ рдФрд░ рдЬреАрд╡рди рдХреЗ рд╕рд╛рде рд░рд╣ рд╕рдХрддреЗ рд╣реИрдВ, рд╣рдо рд╣рдо рд╣рдо рдЬреЛ рд╣рдо рд░рд╣рддреЗ рд╣реИрдВ, рд╣рдо рд╣рдо рдЬреАрд╡рди рдЬреА рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдЬреАрд╡рди рдЬреА рд╕рдХрддреЗ рд╣реИрдВред рдФрд░ рдЬреАрд╡рди рднрд░ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рд╣рдо рдХреНрдпреЛрдВрдХрд┐ рд╣рдо рд╣рдо рдЬреАрд╡рди рдЬреА рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдЬреАрд╡рди рдЬреА рд╕рдХрддреЗ рд╣реИрдВ, рд╣рдо рд╣рдо рд░рд╣рддреЗ рд╣реИрдВред рд╣рдо рдирд╣реАрдВ рд░рд╣ рд╕рдХрддреЗ рд╣реИрдВ, рд╣рдо рдирд╣реАрдВ, рд╣рдо рдирд╣реАрдВ рд╣реИрдВ, рдФрд░ рд╣рдо рдирд╣реАрдВ рд░рд╣ рд╕рдХрддреЗ рд╣реИрдВ, рдФрд░ рд╣рдо рд╣рдо рдирд╣реАрдВ, рд╣рдо рдПрдХ рд╕рд╛рде\n"
     ]
    }
   ],
   "source": [
    "context = \"\"\"\n",
    "рдорд╣рд╛рддреНрдорд╛ рдЧрд╛рдВрдзреА, рдЬрд┐рдиреНрд╣реЗрдВ рдмрд╛рдкреВ рдХрд╣рд╛ рдЬрд╛рддрд╛ рд╣реИ, рднрд╛рд░рдд рдХреЗ рд╕реНрд╡рддрдВрддреНрд░рддрд╛ рд╕рдВрдЧреНрд░рд╛рдо рдХреЗ рдкреНрд░рдореБрдЦ рдиреЗрддрд╛ рдереЗред рдЙрдирдХрд╛ рдЬрдиреНрдо 2 рдЕрдХреНрдЯреВрдмрд░ 1869 рдХреЛ рд╣реБрдЖ рдерд╛ред\n",
    "\"\"\"\n",
    "# рд╕рдВрджрд░реНрдн: {context}\n",
    "\n",
    "question = \"рдорд╣рд╛рддреНрдорд╛ рдЧрд╛рдВрдзреА рдХрд╛ рдЬрдиреНрдо рдХрдм рд╣реБрдЖ рдерд╛? рдЙрдирдХрд╛ рдЬрдиреНрдо 2 рдЕрдХреНрдЯреВрдмрд░ 1869 рдХреЛ рд╣реБрдЖ рдерд╛ред\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "рд╕рд┐рд░реНрдл рдиреАрдЪреЗ рджрд┐рдП рд╕рдВрджрд░реНрдн рд╕реЗ рд╣реА рдЬрд╡рд╛рдм рджреЛред рдЕрдЧрд░ рд╕рдВрджрд░реНрдн рдореЗрдВ рдЙрддреНрддрд░ рдирд╣реАрдВ рд╣реИ рддреЛ рд▓рд┐рдЦреЛ: \"рд╕рдВрджрд░реНрдн рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рдирд╣реАрдВ рд╣реИред\"\n",
    "\n",
    "{context}\n",
    "\n",
    "рдкреНрд░рд╢реНрди: рдЙрдирдХрд╛ рдЬрдиреНрдо 2 рдЕрдХреНрдЯреВрдмрд░ 1869 рдХреЛ рд╣реБрдЖ рдерд╛ред\n",
    "\n",
    "рдЙрддреНрддрд░:\n",
    "\"\"\"\n",
    "\n",
    "prompt_ids = torch.tensor([sp.encode(prompt)], device=DEVICE)\n",
    "max_new = model.decoder.seq_len - prompt_ids.size(1) - 1\n",
    "out = generate(model, prompt_ids, max_new_tokens=max_new)\n",
    "generated_ids = out[0].tolist()\n",
    "answer_ids = generated_ids[len(prompt_ids[0]):]\n",
    "print(sp.decode(answer_ids).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fac7d49-2a38-4ab8-8788-dc712f9ecfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"рдПрдХ рдРрд╕реА рджреБрдирд┐рдпрд╛ рдЬрд╣рд╛рдБ рд╣рдо рд╕рднреА рдЬреАрд╡рд┐рдд рд╣реИрдВ\" рдпрд╛ \"рдЗрд╕ рддрд░рд╣ рдХреЗ рдПрдХ рдЕрджреНрднреБрдд, рд╡рд┐рдЪрд╛рд░рд╢реАрд▓ рдФрд░ рдЖрдХрд░реНрд╖рдХ рд╕рдорд╛рдЬ рдХрд╛ рдирд┐рд░реНрдорд╛рдг рдХрд░рдирд╛\"-рдпрд╣ рд╕реБрдЭрд╛рд╡ рджреЗрддреЗ рд╣реБрдП рдХрд┐ рд╕рднреА рдорд╛рдирд╡ рдФрд░ рдордиреБрд╖реНрдпреЛрдВ рджреНрд╡рд╛рд░рд╛ рдХрд┐рдП рдЧрдП рдХрд╛рд░реНрдпреЛрдВ рдХреЛ рд╣рдо рдорд╣рддреНрд╡ рджреЗрддреЗ рд╣реИрдВ, рдпрд╣ рд╕реБрдЭрд╛рд╡ рджреЗрддрд╛ рд╣реИ рдХрд┐ рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдХреЗрд╡рд▓ рдПрдХ рдЙрджрд╛рд╣рд░рдг рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП рдХрд┐ рд╣рдо рдХреНрдпрд╛ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдпрд╣ рд╣рдореЗрдВ рдЕрдкрдиреЗ рдЖрд╕-рдкрд╛рд╕ рдХреА рджреБрдирд┐рдпрд╛ рдкрд░ рдирд┐рдпрдВрддреНрд░рдг рд░рдЦрдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЛрддреНрд╕рд╛рд╣рд┐рдд рдХрд░рддрд╛ рд╣реИ, рдпрд╣ рдЬрд╛рдирддреЗ рд╣реБрдП рдХрд┐ рд╣рдо рдПрдХ рдмреЗрд╣рддрд░ рдЬрдЧрд╣ рдмрдирд╛ рд╕рдХрддреЗ рд╣реИрдВред тБЗ рдЕрдВрддрддрдГ, рдпрджрд┐ рдХрд┐рд╕реА рд╡реНрдпрдХреНрддрд┐ рдХреЗ рд▓рд┐рдП рдЬреАрд╡рди рдХреА рдЧреБрдгрд╡рддреНрддрд╛ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ, рддреЛ рдпрд╣ рд╣рдореЗрдВ рдЬреАрд╡рди рднрд░ рдХреЗ рд▓рд┐рдП рдЕрдкрдиреА рдкреВрд░реА рдХреНрд╖рдорддрд╛ рддрдХ рдкрд╣реБрдВрдЪрдиреЗ рдФрд░ рдЬреАрд╡рди рдХреЛ рдлрд┐рд░ рд╕реЗ рдЬреАрдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░реЗрд░рд┐рдд рдХрд░рдиреЗ рдореЗрдВ рдорджрдж рдХрд░реЗрдЧрд╛ред рд╣рдореЗрдВ рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рддреЗ рд░рд╣рдиреЗ рдХреЗ рд▓рд┐рдП рдкреНрд░рдпрд╛рд╕ рдХрд░рдиреЗ рдЪрд╛рд╣рд┐рдП рдХрд┐ рд╣рдорд╛рд░реА рдЗрдЪреНрдЫрд╛рдПрдБ рдкреВрд░реА рд╣реЛ рдЬрд╛рдПрдВ, рдФрд░ рд╣рдо рдЗрд╕реЗ рдкреВрд░рд╛ рд╣реЛрдиреЗ рджреЗрдВ! \"рдпрд╣рд╛рдБ рдЗрд╕ рд╕рдВрджрд░реНрдн рдореЗрдВ рдХреБрдЫ рднреА рд╢рд╛рдорд┐рд▓ рд╣реЛрдЧрд╛ рдЬреЛ рд╣рдо рдЪрд╛рд╣рддреЗ рдереЗ, рд▓реЗрдХрд┐рди рд╣рдо рдЗрд╕реЗ рдкреВрд░рд╛ рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдорд┐рд▓рдХрд░ рдХрд╛рдо рдХрд░реЗрдВрдЧреЗред рдпрд╣ рдПрдХ рдРрд╕рд╛ рдЕрдиреБрднрд╡ рд╣реИ рдЬрд┐рд╕реЗ рд╣рдо рд╣рдореЗрд╢рд╛ рдпрд╛рдж рд░рдЦреЗрдВрдЧреЗ рдФрд░ рдПрдХ рдЕрдзрд┐рдХ рд╕рдореГрджреНрдз рднрд╡рд┐рд╖реНрдп рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЗрд╕рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗред \"рд╕рдВрдХреНрд╖реЗрдк рдореЗрдВ, рдпрджрд┐ рдХреЛрдИ рд╡реНрдпрдХреНрддрд┐ рдЕрдкрдиреЗ рд╕реНрд╡рдпрдВ рдХреЗ рд╡рд┐рдЪрд╛рд░реЛрдВ рдХреЛ рд╡реНрдпрдХреНрдд рдХрд░рдиреЗ рдФрд░ рдЕрдкрдиреЗ рдЖрд╕рдкрд╛рд╕ рдХреА рджреБрдирд┐рдпрд╛ рдкрд░ рдирд┐рдпрдВрддреНрд░рдг рд░рдЦрдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдирд╣реАрдВ рд╣реИ, рддреЛ рд╡реЗ рдЗрд╕ рдмрд╛рдд рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░реЗрдВрдЧреЗ рдХрд┐ рд╣рдо рдХреНрдпрд╛ рд╣рд╛рд╕рд┐рд▓ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рдФрд░ рдХреНрдпрд╛ рд╣рд╛рд╕рд┐рд▓ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред \"рдХреБрд▓ рдорд┐рд▓рд╛рдХрд░, \"рдирд╡реАрдиреАрдХрд░рдг, рд╕реНрд╡рдЪреНрдЫ рдФрд░ рд╕реНрд╡рд╕реНрде рдЬреАрд╡рди рд╢реИрд▓реА рдореЗрдВ рд╕реБрдзрд╛рд░ рдХрд░реЗрдВ\" рдпрд╛ \"рдЬрд▓реНрджрдирд╛\" рдЬреИрд╕реЗ рд╡рд╛рдХреНрдпрд╛рдВрд╢ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ, рд╣рдо рдЕрдкрдиреЗ рдЬреАрд╡рди рдореЗрдВ рдЕрдзрд┐рдХ рдЦреБрд╢реА рдФрд░ рд╢рд╛рдВрддрд┐ рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред \"рдФрд░, рдЬрдм рд╣рдо рдПрдХ рд╕рд╛рде рд░рд╣рддреЗ рд╣реИрдВ, рддреЛ рд╣рдо рдЕрдкрдиреЗ рдЬреАрд╡рди рдореЗрдВ рдЕрдзрд┐рдХ рдЦреБрд╢реА рдкрд╛рддреЗ рд╣реИрдВ рдФрд░ рдЬреАрд╡рди рдЬреА рд░рд╣реЗ рд╣реЛрддреЗ рд╣реИрдВред \"рддреЛ, рд╣рдо рдЬреЛ рдХреБрдЫ рднреА рдЬрд╛рдирддреЗ рд╣реИрдВ рдХрд┐ рд╣рдо рдЬреЛ рдПрдХ рд╕рд╛рде рдмрд╛рддрдЪреАрдд рдХрд░рддреЗ рд╣реИрдВ, рд╣рдо рдЬреАрд╡рди рдХреА рдЪреБрдиреМрддрд┐рдпреЛрдВ рдХрд╛ рдЖрдирдВрдж рд▓реЗрддреЗ рд╣реИрдВред \"рдЖрдиреЗ рдХреЗ рд▓рд┐рдП рдХреБрдЫ рдЕрд▓рдЧ рдорд╣рд╕реВрд╕ рдХрд░рддреЗ рд╣реИрдВ, рд╣рдо рдЕрдкрдиреЗ рдЖрдк рдЬреЛ рд╣рдо рдЬреЛ рдХреБрдЫ рд╕рдордп рд╕рд╛рдЭрд╛ рдХрд░рддреЗ рд╣реИрдВред рдФрд░ рдЕрдкрдиреЗ рд░рд╛рд╕реНрддреЗ рджреЛрдиреЛрдВ рдХреЗ рдорд╛рдзреНрдпрдо рдмрдирд╛рддреЗ рд╣реИрдВред рд╣рдо рдПрдХ-рджреВрд╕рд░реЗ рдЦрд╛рддреЗ рд╣реИрдВред \"рдЕрдкрдиреЗ рдЬреАрд╡рди рдореЗрдВ рдЬреАрд╡рди рдореЗрдВ рд░рд╣рддреЗ рд╣реИрдВред \"рд╣рдо рд╣реЛрддреЗ рд╣реИрдВ, рд╣рдо рдФрд░ рдЕрдкрдиреЗ рдЬреАрд╡рди рдХреЗ рд╕рд╛рде рд░рд╣рддреЗ рд╣реИрдВ, рд╣рдо рдПрдХ-рдмрддреЗ рд╣реИрдВред рд╣рдо рд╣рдо рдПрдХ рд╕рд╛рде рд░рд╣ рд╕рдХрддреЗ рд╣реИрдВ, рд╣рдо рдПрдХ рджреВрд╕рд░реЗ рд╣рдо рд░рд╣рддреЗ рд╣реИрдВ, рдФрд░\n"
     ]
    }
   ],
   "source": [
    "# prompt = \"\"\"\n",
    "# рдЖрдк рдПрдХ рдкреНрд░рддрд┐рднрд╛рд╢рд╛рд▓реА рдХрд╣рд╛рдиреАрдХрд╛рд░ рд╣реИрдВред рдХреГрдкрдпрд╛ рдПрдХ рд░реЛрдЪрдХ рдФрд░ рд╕реБрдВрджрд░ рд╣рд┐рдВрджреА рдХрд╣рд╛рдиреА рд▓рд┐рдЦреЗрдВред рдХрд╣рд╛рдиреА рдХреА рд╢реБрд░реБрдЖрдд рдПрдХ рдЫреЛрдЯреЗ рд╕реЗ рдЧрд╛рдБрд╡ рд╕реЗ рд╣реЛрддреА рд╣реИ, рдЬрд┐рд╕рдореЗрдВ рдПрдХ рдирд╛рдпрдХ рдпрд╛ рдирд╛рдпрд┐рдХрд╛ рд╣реЛрддрд╛ рд╣реИ рдЬреЛ рдПрдХ рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЪреБрдиреМрддреА рдХрд╛ рд╕рд╛рдордирд╛ рдХрд░рддрд╛ рд╣реИред рдХрд╣рд╛рдиреА рдореЗрдВ рднрд╛рд╡рдирд╛рдПрдБ, рд░реЛрдорд╛рдВрдЪ рдФрд░ рдЬреАрд╡рди рдХреЗ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╕рдмрдХ рд╢рд╛рдорд┐рд▓ рд╣реЛрдВред\n",
    "\n",
    "# рдХрд╣рд╛рдиреА рд╢реБрд░реВ рдХрд░реЗрдВ:\n",
    "# \"\"\"\n",
    "\n",
    "# prompt = \"рдПрдХ рдЦреВрдмрд╕реВрд░рдд рдФрд░ рднрд╛рд╡рдирд╛рддреНрдордХ рд╣рд┐рдВрджреА рдХрд╡рд┐рддрд╛ рд▓рд┐рдЦреЛ рдЬреЛ рдкреНрд░рдХреГрддрд┐ рдХреА рд╕реБрдВрджрд░рддрд╛ рдФрд░ рдЬреАрд╡рди рдХреЗ рд░рдВрдЧреЛрдВ рдХреЛ рджрд░реНрд╢рд╛рдПред рдХрд╡рд┐рддрд╛ рдореЗрдВ рд╕рд░рд▓ рднрд╛рд╖рд╛ рдФрд░ рдЧрд╣рд░реЗ рдЕрд░реНрде рд╣реЛрдВред\"\n",
    "\n",
    "context = \"\"\"\n",
    "рдорд╣рд╛рддреНрдорд╛ рдЧрд╛рдВрдзреА, рдЬрд┐рдиреНрд╣реЗрдВ рдмрд╛рдкреВ рдХрд╣рд╛ рдЬрд╛рддрд╛ рд╣реИ, рднрд╛рд░рдд рдХреЗ рд╕реНрд╡рддрдВрддреНрд░рддрд╛ рд╕рдВрдЧреНрд░рд╛рдо рдХреЗ рдкреНрд░рдореБрдЦ рдиреЗрддрд╛ рдереЗред рдЙрдирдХрд╛ рдЬрдиреНрдо 2 рдЕрдХреНрдЯреВрдмрд░ 1869 рдХреЛ рд╣реБрдЖ рдерд╛ред\n",
    "\"\"\"\n",
    "# рд╕рдВрджрд░реНрдн: {context}\n",
    "\n",
    "question = \"рдорд╣рд╛рддреНрдорд╛ рдЧрд╛рдВрдзреА рдХрд╛ рдЬрдиреНрдо рдХрдм рд╣реБрдЖ рдерд╛? рдЙрдирдХрд╛ рдЬрдиреНрдо 2 рдЕрдХреНрдЯреВрдмрд░ 1869 рдХреЛ рд╣реБрдЖ рдерд╛ред\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "рд╕рд┐рд░реНрдл рдиреАрдЪреЗ рджрд┐рдП рд╕рдВрджрд░реНрдн рд╕реЗ рд╣реА рдЬрд╡рд╛рдм рджреЛред рдЕрдЧрд░ рд╕рдВрджрд░реНрдн рдореЗрдВ рдЙрддреНрддрд░ рдирд╣реАрдВ рд╣реИ рддреЛ рд▓рд┐рдЦреЛ: \"рд╕рдВрджрд░реНрдн рдореЗрдВ рдЬрд╛рдирдХрд╛рд░реА рдирд╣реАрдВ рд╣реИред\"\n",
    "\n",
    "рдкреНрд░рд╢реНрди: рдПрдХ рдЦреВрдмрд╕реВрд░рдд рдФрд░ рднрд╛рд╡рдирд╛рддреНрдордХ рд╣рд┐рдВрджреА рдХрд╡рд┐рддрд╛ рд▓рд┐рдЦреЛ рдЬреЛ рдкреНрд░рдХреГрддрд┐ рдХреА рд╕реБрдВрджрд░рддрд╛ рдФрд░ рдЬреАрд╡рди рдХреЗ рд░рдВрдЧреЛрдВ рдХреЛ рджрд░реНрд╢рд╛рдПред рдХрд╡рд┐рддрд╛ рдореЗрдВ рд╕рд░рд▓ рднрд╛рд╖рд╛ рдФрд░ рдЧрд╣рд░реЗ рдЕрд░реНрде рд╣реЛрдВред\n",
    "\n",
    "рдЙрддреНрддрд░:\n",
    "\"\"\"\n",
    "\n",
    "prompt_ids = torch.tensor([sp.encode(prompt)], device=DEVICE)\n",
    "max_new = model.decoder.seq_len - prompt_ids.size(1) - 1\n",
    "out = generate(model, prompt_ids, max_new_tokens=max_new)\n",
    "generated_ids = out[0].tolist()\n",
    "story = generated_ids[len(prompt_ids[0]):]\n",
    "print(sp.decode(story).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c7afaf-098d-4317-99d9-174d2fdecbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' тБЗ '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.decode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7ca4b-f002-4e30-b49c-922c7dfd7617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
